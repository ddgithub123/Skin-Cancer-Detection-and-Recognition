{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59341728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:04.505177Z",
     "iopub.status.busy": "2026-02-16T06:39:04.504936Z",
     "iopub.status.idle": "2026-02-16T06:39:05.216668Z",
     "shell.execute_reply": "2026-02-16T06:39:05.216098Z"
    },
    "papermill": {
     "duration": 0.717299,
     "end_time": "2026-02-16T06:39:05.218287",
     "exception": false,
     "start_time": "2026-02-16T06:39:04.500988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_path = \"/kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000\"\n",
    "\n",
    "metadata = pd.read_csv(\"/kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6294ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:05.224859Z",
     "iopub.status.busy": "2026-02-16T06:39:05.224239Z",
     "iopub.status.idle": "2026-02-16T06:39:17.281505Z",
     "shell.execute_reply": "2026-02-16T06:39:17.280593Z"
    },
    "papermill": {
     "duration": 12.062068,
     "end_time": "2026-02-16T06:39:17.283008",
     "exception": false,
     "start_time": "2026-02-16T06:39:05.220940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                          image_path  \n",
      "0  /kaggle/input/datasets/kmader/skin-cancer-mnis...  \n",
      "1  /kaggle/input/datasets/kmader/skin-cancer-mnis...  \n",
      "2  /kaggle/input/datasets/kmader/skin-cancer-mnis...  \n",
      "3  /kaggle/input/datasets/kmader/skin-cancer-mnis...  \n",
      "4  /kaggle/input/datasets/kmader/skin-cancer-mnis...  \n"
     ]
    }
   ],
   "source": [
    "# Correct base path\n",
    "base_path = \"/kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000/\"\n",
    "\n",
    "image_dir_1 = base_path + \"HAM10000_images_part_1/\"\n",
    "image_dir_2 = base_path + \"HAM10000_images_part_2/\"\n",
    "\n",
    "def get_image_path(image_id):\n",
    "    path1 = image_dir_1 + image_id + \".jpg\"\n",
    "    path2 = image_dir_2 + image_id + \".jpg\"\n",
    "    \n",
    "    if os.path.exists(path1):\n",
    "        return path1\n",
    "    else:\n",
    "        return path2\n",
    "\n",
    "# Recreate image_path column\n",
    "metadata[\"image_path\"] = metadata[\"image_id\"].apply(get_image_path)\n",
    "\n",
    "# Verify first few rows\n",
    "print(metadata.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0568b27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:17.291611Z",
     "iopub.status.busy": "2026-02-16T06:39:17.291324Z",
     "iopub.status.idle": "2026-02-16T06:39:17.299267Z",
     "shell.execute_reply": "2026-02-16T06:39:17.298484Z"
    },
    "papermill": {
     "duration": 0.015706,
     "end_time": "2026-02-16T06:39:17.303012",
     "exception": false,
     "start_time": "2026-02-16T06:39:17.287306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx\n",
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(metadata[\"dx\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454261b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:17.313914Z",
     "iopub.status.busy": "2026-02-16T06:39:17.313692Z",
     "iopub.status.idle": "2026-02-16T06:39:17.324107Z",
     "shell.execute_reply": "2026-02-16T06:39:17.323343Z"
    },
    "papermill": {
     "duration": 0.0171,
     "end_time": "2026-02-16T06:39:17.325370",
     "exception": false,
     "start_time": "2026-02-16T06:39:17.308270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8902\n",
      "1    1113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create binary label: 1 = melanoma, 0 = others\n",
    "metadata[\"label\"] = metadata[\"dx\"].apply(lambda x: 1 if x == \"mel\" else 0)\n",
    "\n",
    "# Check distribution\n",
    "print(metadata[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7803527d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:17.332114Z",
     "iopub.status.busy": "2026-02-16T06:39:17.331597Z",
     "iopub.status.idle": "2026-02-16T06:39:18.637156Z",
     "shell.execute_reply": "2026-02-16T06:39:18.636202Z"
    },
    "papermill": {
     "duration": 1.310844,
     "end_time": "2026-02-16T06:39:18.638627",
     "exception": false,
     "start_time": "2026-02-16T06:39:17.327783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7010\n",
      "Validation size: 1002\n",
      "Test size: 2003\n",
      "\n",
      "Train distribution:\n",
      "label\n",
      "0    6231\n",
      "1     779\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation distribution:\n",
      "label\n",
      "0    891\n",
      "1    111\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "label\n",
      "0    1780\n",
      "1     223\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: Train (80%) and Test (20%)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    metadata,\n",
    "    test_size=0.2,\n",
    "    stratify=metadata['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Train (70%) and Validation (10%) from remaining\n",
    "val_relative_size = 0.1 / 0.8  # because 10% of total\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=val_relative_size,\n",
    "    stratify=train_val_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "print(\"\\nTrain distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nValidation distribution:\")\n",
    "print(val_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nTest distribution:\")\n",
    "print(test_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4635287b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:18.645193Z",
     "iopub.status.busy": "2026-02-16T06:39:18.644808Z",
     "iopub.status.idle": "2026-02-16T06:39:43.639276Z",
     "shell.execute_reply": "2026-02-16T06:39:43.638487Z"
    },
    "papermill": {
     "duration": 24.999495,
     "end_time": "2026-02-16T06:39:43.640770",
     "exception": false,
     "start_time": "2026-02-16T06:39:18.641275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-16 06:39:20.109920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771223960.289875      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771223960.340469      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771223960.751289      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771223960.751328      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771223960.751331      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771223960.751333      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7010 validated image filenames.\n",
      "Found 1002 validated image filenames.\n",
      "Found 2003 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Training generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation + Test generator (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113ca92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:43.648125Z",
     "iopub.status.busy": "2026-02-16T06:39:43.647486Z",
     "iopub.status.idle": "2026-02-16T06:39:43.656405Z",
     "shell.execute_reply": "2026-02-16T06:39:43.655825Z"
    },
    "papermill": {
     "duration": 0.013913,
     "end_time": "2026-02-16T06:39:43.657681",
     "exception": false,
     "start_time": "2026-02-16T06:39:43.643768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {np.int64(0): np.float64(0.5625100304926978), np.int64(1): np.float64(4.499358151476252)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(train_df['label'])\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=train_df['label']\n",
    ")\n",
    "\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6daf7e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:43.664252Z",
     "iopub.status.busy": "2026-02-16T06:39:43.663992Z",
     "iopub.status.idle": "2026-02-16T06:39:44.369733Z",
     "shell.execute_reply": "2026-02-16T06:39:44.368885Z"
    },
    "papermill": {
     "duration": 0.710892,
     "end_time": "2026-02-16T06:39:44.371346",
     "exception": false,
     "start_time": "2026-02-16T06:39:43.660454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6814fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:44.378389Z",
     "iopub.status.busy": "2026-02-16T06:39:44.378157Z",
     "iopub.status.idle": "2026-02-16T06:39:44.840931Z",
     "shell.execute_reply": "2026-02-16T06:39:44.840146Z"
    },
    "papermill": {
     "duration": 0.468022,
     "end_time": "2026-02-16T06:39:44.842492",
     "exception": false,
     "start_time": "2026-02-16T06:39:44.374470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771223984.794280      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1771223984.800123      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Enable multi-GPU strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices:\", strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341ea70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:44.849915Z",
     "iopub.status.busy": "2026-02-16T06:39:44.849475Z",
     "iopub.status.idle": "2026-02-16T06:39:48.592141Z",
     "shell.execute_reply": "2026-02-16T06:39:48.591472Z"
    },
    "papermill": {
     "duration": 3.747994,
     "end_time": "2026-02-16T06:39:48.593551",
     "exception": false,
     "start_time": "2026-02-16T06:39:44.845557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,383,908</span> (16.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,383,908\u001b[0m (16.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,265</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,265\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,643</span> (15.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,052,643\u001b[0m (15.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # IMPORTANT: dtype float32 for stability\n",
    "    outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a125c49b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T06:39:48.602334Z",
     "iopub.status.busy": "2026-02-16T06:39:48.601746Z",
     "iopub.status.idle": "2026-02-16T07:05:26.260236Z",
     "shell.execute_reply": "2026-02-16T07:05:26.259346Z"
    },
    "papermill": {
     "duration": 1537.664934,
     "end_time": "2026-02-16T07:05:26.262300",
     "exception": false,
     "start_time": "2026-02-16T06:39:48.597366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/12\n",
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771224007.602030      67 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "I0000 00:00:1771224007.602142      68 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4812 - auc: 0.4808 - loss: 0.9070\n",
      "Epoch 1: val_auc improved from -inf to 0.50282, saving model to /kaggle/working/binary_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.4812 - auc: 0.4808 - loss: 0.9070 - val_accuracy: 0.1108 - val_auc: 0.5028 - val_loss: 0.7452 - learning_rate: 1.0000e-04\n",
      "Epoch 2/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4971 - auc: 0.5215 - loss: 0.8416\n",
      "Epoch 2: val_auc improved from 0.50282 to 0.50847, saving model to /kaggle/working/binary_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.4971 - auc: 0.5214 - loss: 0.8415 - val_accuracy: 0.1108 - val_auc: 0.5085 - val_loss: 0.7114 - learning_rate: 1.0000e-04\n",
      "Epoch 3/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5203 - auc: 0.5063 - loss: 0.8215\n",
      "Epoch 3: val_auc improved from 0.50847 to 0.57939, saving model to /kaggle/working/binary_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.5201 - auc: 0.5064 - loss: 0.8216 - val_accuracy: 0.1108 - val_auc: 0.5794 - val_loss: 0.7282 - learning_rate: 1.0000e-04\n",
      "Epoch 4/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5027 - auc: 0.4983 - loss: 0.8445\n",
      "Epoch 4: val_auc did not improve from 0.57939\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.5027 - auc: 0.4984 - loss: 0.8443 - val_accuracy: 0.1108 - val_auc: 0.5000 - val_loss: 0.7337 - learning_rate: 1.0000e-04\n",
      "Epoch 5/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5148 - auc: 0.5064 - loss: 0.7834\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 5: val_auc did not improve from 0.57939\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.5148 - auc: 0.5065 - loss: 0.7836 - val_accuracy: 0.1108 - val_auc: 0.5069 - val_loss: 0.7168 - learning_rate: 1.0000e-04\n",
      "Epoch 6/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5018 - auc: 0.5072 - loss: 0.8097\n",
      "Epoch 6: val_auc improved from 0.57939 to 0.65453, saving model to /kaggle/working/binary_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5018 - auc: 0.5070 - loss: 0.8097 - val_accuracy: 0.1437 - val_auc: 0.6545 - val_loss: 0.7007 - learning_rate: 5.0000e-05\n",
      "Epoch 7/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5005 - auc: 0.4838 - loss: 0.8151\n",
      "Epoch 7: val_auc improved from 0.65453 to 0.67720, saving model to /kaggle/working/binary_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 1s/step - accuracy: 0.5005 - auc: 0.4838 - loss: 0.8152 - val_accuracy: 0.1657 - val_auc: 0.6772 - val_loss: 0.7024 - learning_rate: 5.0000e-05\n",
      "Epoch 8/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4947 - auc: 0.5439 - loss: 0.7980\n",
      "Epoch 8: val_auc did not improve from 0.67720\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.4947 - auc: 0.5438 - loss: 0.7979 - val_accuracy: 0.4900 - val_auc: 0.6761 - val_loss: 0.6936 - learning_rate: 5.0000e-05\n",
      "Epoch 9/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5125 - auc: 0.5226 - loss: 0.7720\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 9: val_auc did not improve from 0.67720\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.5124 - auc: 0.5225 - loss: 0.7722 - val_accuracy: 0.1108 - val_auc: 0.6431 - val_loss: 0.7300 - learning_rate: 5.0000e-05\n",
      "Epoch 10/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4975 - auc: 0.5154 - loss: 0.7925\n",
      "Epoch 10: val_auc did not improve from 0.67720\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.4975 - auc: 0.5153 - loss: 0.7926 - val_accuracy: 0.1108 - val_auc: 0.6430 - val_loss: 0.7296 - learning_rate: 2.5000e-05\n",
      "Epoch 11/12\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5035 - auc: 0.5135 - loss: 0.7593\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 11: val_auc did not improve from 0.67720\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.5034 - auc: 0.5136 - loss: 0.7595 - val_accuracy: 0.1108 - val_auc: 0.6619 - val_loss: 0.7230 - learning_rate: 2.5000e-05\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        patience=4,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        '/kaggle/working/binary_best_model.h5',\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=12,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca07af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:05:26.371825Z",
     "iopub.status.busy": "2026-02-16T07:05:26.371481Z",
     "iopub.status.idle": "2026-02-16T07:05:26.381667Z",
     "shell.execute_reply": "2026-02-16T07:05:26.380790Z"
    },
    "papermill": {
     "duration": 0.067816,
     "end_time": "2026-02-16T07:05:26.383355",
     "exception": false,
     "start_time": "2026-02-16T07:05:26.315539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers: 9\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze top 30 layers\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"Trainable layers:\", len([l for l in model.layers if l.trainable]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ea79f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:05:26.491827Z",
     "iopub.status.busy": "2026-02-16T07:05:26.491040Z",
     "iopub.status.idle": "2026-02-16T07:05:26.597108Z",
     "shell.execute_reply": "2026-02-16T07:05:26.596395Z"
    },
    "papermill": {
     "duration": 0.162971,
     "end_time": "2026-02-16T07:05:26.598838",
     "exception": false,
     "start_time": "2026-02-16T07:05:26.435867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1962ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:05:26.709158Z",
     "iopub.status.busy": "2026-02-16T07:05:26.708323Z",
     "iopub.status.idle": "2026-02-16T07:18:54.002271Z",
     "shell.execute_reply": "2026-02-16T07:18:54.001296Z"
    },
    "papermill": {
     "duration": 807.350021,
     "end_time": "2026-02-16T07:18:54.004155",
     "exception": false,
     "start_time": "2026-02-16T07:05:26.654134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "INFO:tensorflow:Collective all_reduce tensors: 36 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 36 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.4926 - auc: 0.5194 - loss: 0.8787 - val_accuracy: 0.8892 - val_auc: 0.6402 - val_loss: 0.4171 - learning_rate: 1.0000e-05\n",
      "Epoch 2/8\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.4835 - auc: 0.4957 - loss: 0.8398 - val_accuracy: 0.8892 - val_auc: 0.6721 - val_loss: 0.4021 - learning_rate: 1.0000e-05\n",
      "Epoch 3/8\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 1s/step - accuracy: 0.5121 - auc: 0.5209 - loss: 0.8375 - val_accuracy: 0.8892 - val_auc: 0.6748 - val_loss: 0.3713 - learning_rate: 1.0000e-05\n",
      "Epoch 4/8\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - accuracy: 0.4905 - auc: 0.5229 - loss: 0.7945 - val_accuracy: 0.8892 - val_auc: 0.6179 - val_loss: 0.3775 - learning_rate: 1.0000e-05\n",
      "Epoch 5/8\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4961 - auc: 0.5129 - loss: 0.8268\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.4961 - auc: 0.5130 - loss: 0.8268 - val_accuracy: 0.8892 - val_auc: 0.4910 - val_loss: 0.4621 - learning_rate: 1.0000e-05\n",
      "Epoch 6/8\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.5073 - auc: 0.5160 - loss: 0.8306 - val_accuracy: 0.8892 - val_auc: 0.6011 - val_loss: 0.5546 - learning_rate: 5.0000e-06\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    }
   ],
   "source": [
    "fine_tune_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=8,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=fine_tune_callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f652045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:18:54.167289Z",
     "iopub.status.busy": "2026-02-16T07:18:54.166871Z",
     "iopub.status.idle": "2026-02-16T07:18:54.178293Z",
     "shell.execute_reply": "2026-02-16T07:18:54.177492Z"
    },
    "papermill": {
     "duration": 0.093139,
     "end_time": "2026-02-16T07:18:54.179773",
     "exception": false,
     "start_time": "2026-02-16T07:18:54.086634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history.csv saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert history to DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Save to Kaggle working directory\n",
    "history_df.to_csv('/kaggle/working/history.csv', index=False)\n",
    "\n",
    "print(\"history.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8a07de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:18:54.340242Z",
     "iopub.status.busy": "2026-02-16T07:18:54.339555Z",
     "iopub.status.idle": "2026-02-16T07:19:41.438379Z",
     "shell.execute_reply": "2026-02-16T07:19:41.437547Z"
    },
    "papermill": {
     "duration": 47.182412,
     "end_time": "2026-02-16T07:19:41.439974",
     "exception": false,
     "start_time": "2026-02-16T07:18:54.257562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step\n",
      "test_predictions.csv saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.labels\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_proba = model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Convert probabilities to class predictions\n",
    "y_pred = (y_pred_proba.flatten() > 0.5).astype(int)\n",
    "\n",
    "# Create DataFrame\n",
    "test_results_df = pd.DataFrame({\n",
    "    'true_label': y_true,\n",
    "    'predicted_label': y_pred,\n",
    "    'probability': y_pred_proba.flatten()\n",
    "})\n",
    "\n",
    "# Save file\n",
    "test_results_df.to_csv('/kaggle/working/test_predictions.csv', index=False)\n",
    "\n",
    "print(\"test_predictions.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d56824a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T07:19:41.608346Z",
     "iopub.status.busy": "2026-02-16T07:19:41.608003Z",
     "iopub.status.idle": "2026-02-16T07:19:41.994484Z",
     "shell.execute_reply": "2026-02-16T07:19:41.993582Z"
    },
    "papermill": {
     "duration": 0.470529,
     "end_time": "2026-02-16T07:19:41.996138",
     "exception": false,
     "start_time": "2026-02-16T07:19:41.525609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "model.save('/kaggle/working/binary_model_final.h5')\n",
    "print(\"Model saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2443.932183,
   "end_time": "2026-02-16T07:19:46.085310",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-16T06:39:02.153127",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
